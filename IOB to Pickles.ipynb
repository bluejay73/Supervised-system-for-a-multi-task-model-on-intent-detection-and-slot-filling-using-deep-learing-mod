{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = []\n",
    "with open('ATIS_train.iob','r') as f:\n",
    "    for line in f:\n",
    "        raw_train.append(line)\n",
    "        \n",
    "raw_test = []\n",
    "with open('ATIS_test.iob','r') as f:\n",
    "    for line in f:\n",
    "        raw_test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(893,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "replace_dic = {'\\'d' : \"would\" , '\\'s' : \"is\" , '\\'t' : \"not\"}\n",
    "for sentence in raw_train:\n",
    "    sentence = sentence.split('\\t')[0][4:-4]\n",
    "    words = sentence.split(' ')\n",
    "    new_sentence = \"\"\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        word = word.split(\"'\")[0]\n",
    "        if(word == ''):\n",
    "            print word\n",
    "            continue;\n",
    "        if(word in replace_dic):\n",
    "            print(word)\n",
    "            word = replace_dic[word];\n",
    "        if(word.isdigit()):\n",
    "            word = \"number\"\n",
    "        new_sentence = new_sentence + \" \" + word\n",
    "    train.append(new_sentence[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5871,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "replace_dic = {'\\'d' : \"would\" , '\\'s' : \"is\" , '\\'t' : \"not\"}\n",
    "for sentence in raw_test:\n",
    "    sentence = sentence.split('\\t')[0][4:-4]\n",
    "    words = sentence.split(' ')\n",
    "    new_sentence = \"\"\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        word = word.split(\"'\")[0]\n",
    "        if(word == ''):\n",
    "            continue;\n",
    "        if(word in replace_dic):\n",
    "            word = replace_dic[word];\n",
    "        if(word.isdigit()):\n",
    "            word = \"number\"\n",
    "        new_sentence = new_sentence + \" \" + word\n",
    "    test.append(new_sentence[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sinchan/Videos/slot_filling/train_data.pickle', 'w+') as fp:\n",
    "     pickle.dump(train,fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/test_data.pickle', 'w+') as fp:\n",
    "     pickle.dump(test,fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sinchan/Videos/slot_filling/train_data.pickle', 'r+') as fp:\n",
    "    train = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/test_data.pickle', 'r+') as fp:\n",
    "    test = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i would like to find a flight from charlotte to las vegas that makes a stop in st. louis'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOS i would like to find a flight from charlotte to las vegas that makes a stop in st. louis EOS\\tO O O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O O O O B-stoploc.city_name I-stoploc.city_name atis_flight\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw_train + raw_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(word):\n",
    "    replace_dic = {'\\'d' : \"would\" , '\\'s' : \"is\" , '\\'t' : \"not\"}\n",
    "    word = word.split(\"'\")[0]\n",
    "    if(word == ''):\n",
    "        return word\n",
    "    if(word in replace_dic):\n",
    "        word = replace_dic[word];\n",
    "    if(word.isdigit()):\n",
    "        word = \"number\"\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_dict = dict()\n",
    "word_dict = dict()\n",
    "\n",
    "i_s = 0\n",
    "i_w = 1\n",
    "\n",
    "for utterance in raw:\n",
    "    t = utterance.split('\\t')\n",
    "    words = t[0].strip().split(' ')\n",
    "    slots = t[1].strip().split(' ')\n",
    "    n = len(words)\n",
    "    for i in xrange(n):\n",
    "        word = check(words[i])\n",
    "        if(word not in word_dict):\n",
    "            word_dict[word] = i_w\n",
    "            i_w = i_w + 1\n",
    "    for i in xrange(n-1):\n",
    "        if(slots[i] not in slot_dict):\n",
    "            slot_dict[slots[i]] = i_s\n",
    "            i_s = i_s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = [slot_dict,word_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sinchan/Videos/slot_filling/slot_word_dict.pickle', 'w+') as fp:\n",
    "    pickle.dump(dicts,fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sinchan/Videos/slot_filling/slot_word_dict.pickle', 'r+') as fp:\n",
    "    dicts = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_dict,word_dict = dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slot_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(data,word_dict):\n",
    "    sequences = list()\n",
    "    for sentence in data:\n",
    "        sequence = list()\n",
    "        for word in words:\n",
    "                sequence.append(word_dict[word])\n",
    "        sequences.append(sequence)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = make_sequences(train,word_dict)\n",
    "test_sequence = make_sequences(test,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to fly from boston at number am and arrive in denver at number in the morning'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_sequence = make_sequences(train,word_dict)\n",
    "test_sequence = make_sequences(test,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 81,\n",
       " 82,\n",
       " 4,\n",
       " 111,\n",
       " 46,\n",
       " 32,\n",
       " 6,\n",
       " 144,\n",
       " 4,\n",
       " 260,\n",
       " 261,\n",
       " 143,\n",
       " 345,\n",
       " 46,\n",
       " 223,\n",
       " 13,\n",
       " 115,\n",
       " 116]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sinchan/Videos/slot_filling/train_sequence.pickle', 'w+') as fp:\n",
    "     pickle.dump(train_sequence,fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/test_sequence.pickle', 'w+') as fp:\n",
    "     pickle.dump(test_sequence,fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sinchan/Videos/slot_filling/train_sequence.pickle', 'r+') as fp:\n",
    "    train_sequence = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/test_sequence.pickle', 'r+') as fp:\n",
    "    test_sequence = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = train_sequence + test_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "lens = list()\n",
    "for sequence in sequences:\n",
    "    lens.append(len(sequence))\n",
    "    m = max(len(sequence),m)\n",
    "    \n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2929e78d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.hist(lens,46)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Output in One-Hot form(Slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOS find me a flight that flies from memphis to tacoma EOS',\n",
       " 'O O O O O O O O B-fromloc.city_name O B-toloc.city_name atis_flight\\n']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance = raw_train[0]\n",
    "slots = utterance.split('\\t')[1].strip().split(' ')[:-1]\n",
    "slots = t\n",
    "slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(slot_dict)\n",
    "\n",
    "y_train_slot = list()\n",
    "for utterance in raw_train:\n",
    "    outs = list()\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[:-1]\n",
    "    for slot in slots:\n",
    "        out = np.zeros(n)\n",
    "        out = list(out)\n",
    "        out[slot_dict[slot]] = 1\n",
    "        outs.append(out) \n",
    "    y_train_slot.append(outs)\n",
    "    \n",
    "y_test_slot = list()\n",
    "for utterance in raw_test:\n",
    "    outs = list()\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[:-1]\n",
    "    for slot in slots:\n",
    "        out = np.zeros(n)\n",
    "        out = list(out)\n",
    "        out[slot_dict[slot]] = 1\n",
    "        outs.append(out) \n",
    "    y_test_slot.append(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 127)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train_slot[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e867e6726007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_val' is not defined"
     ]
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combine_slot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9f9e98ec1d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_slot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combine_slot' is not defined"
     ]
    }
   ],
   "source": [
    "len(combine_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make POS_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = dict()\n",
    "i = 0\n",
    "\n",
    "for utterance in train + test:\n",
    "    tags = nltk.pos_tag(utterance.split(' '))\n",
    "    for tag in tags:\n",
    "        tag = tag[1]\n",
    "        if(tag not in pos_dict):\n",
    "            pos_dict[tag] = i\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CC': 5,\n",
       " 'CD': 21,\n",
       " 'DT': 6,\n",
       " 'EX': 22,\n",
       " 'FW': 28,\n",
       " 'IN': 4,\n",
       " 'JJ': 9,\n",
       " 'JJR': 26,\n",
       " 'JJS': 12,\n",
       " 'MD': 15,\n",
       " 'NN': 0,\n",
       " 'NNP': 25,\n",
       " 'NNS': 8,\n",
       " 'PDT': 20,\n",
       " 'PRP': 14,\n",
       " 'PRP$': 27,\n",
       " 'RB': 17,\n",
       " 'RBR': 29,\n",
       " 'RBS': 19,\n",
       " 'RP': 24,\n",
       " 'TO': 2,\n",
       " 'UH': 30,\n",
       " 'VB': 3,\n",
       " 'VBD': 23,\n",
       " 'VBG': 11,\n",
       " 'VBN': 13,\n",
       " 'VBP': 1,\n",
       " 'VBZ': 10,\n",
       " 'WDT': 16,\n",
       " 'WP': 7,\n",
       " 'WRB': 18}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(pos_dict)\n",
    "max_len = 46\n",
    "\n",
    "x_train_pos = list()\n",
    "for utterance in train:\n",
    "    outs = np.zeros((max_len,len(pos_dict)))\n",
    "#     outs = list(outs)\n",
    "    tags = nltk.pos_tag(utterance.split(' '))\n",
    "    for i in range(len(tags)):\n",
    "        outs[i][pos_dict[tags[i][1]]] = 1\n",
    "    x_train_pos.append(outs)\n",
    "    \n",
    "x_test_pos = list()\n",
    "for utterance in test:\n",
    "    outs = np.zeros((max_len,len(pos_dict)))\n",
    "#     outs = list(outs)\n",
    "    tags = nltk.pos_tag(utterance.split(' '))\n",
    "    for i in range(len(tags)):\n",
    "        outs[i][pos_dict[tags[i][1]]] = 1\n",
    "    x_test_pos.append(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cheapest airfare from tacoma to orlando'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pos[3][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-711d2c0bc291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "def make_sequences(data,word_dict):\n",
    "    sequences = list()\n",
    "    for sentence in data:\n",
    "        sequence = list()\n",
    "        words = sentence.split(' ')\n",
    "        for word in words:\n",
    "                sequence.append(word_dict[word])\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "train_sequence = pad_sequences(train_sequence, maxlen = 46, padding='post')\n",
    "test_sequence = pad_sequences(test_sequence, maxlen = 46, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "EXTRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinchan/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, pickle, sys, json, random, math \n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# from keras.np_utils import probas_to_classes\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Conv1D,Conv2D, MaxPooling1D,MaxPooling2D, Embedding, LSTM, add, concatenate, TimeDistributed, Bidirectional,Reshape\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.layers import Dense, Input, Flatten, Merge, Dropout, concatenate, Concatenate\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/embedding_matrix_m.pickle', 'r+') as fp:\n",
    "    embedding_matrix = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/embedding_matrix_mw.pickle', 'r+') as fp:\n",
    "    embedding_matrix_w = pickle.load(fp)\n",
    "fp.close()\n",
    "with open('/home/sinchan/Videos/slot_filling/embedding_matrix_mg.pickle', 'r+') as fp:\n",
    "    embedding_matrix_g = pickle.load(fp)\n",
    "fp.close()\n",
    "with open('/home/sinchan/Videos/slot_filling/train_sequence.pickle', 'r+') as fp:\n",
    "    train_sequence = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/test_sequence.pickle', 'r+') as fp:\n",
    "    test_sequence = pickle.load(fp)\n",
    "fp.close()\n",
    "\n",
    "with open('/home/sinchan/Videos/slot_filling/slot_word_dict.pickle', 'r+') as fp:\n",
    "    slot_word_dict = pickle.load(fp)\n",
    "fp.close()\n",
    "train_sequence = pad_sequences(train_sequence, maxlen = 46, padding='post')\n",
    "test_sequence = pad_sequences(test_sequence, maxlen = 46, padding='post') \n",
    "\n",
    "max_len = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(slot_dict)\n",
    "\n",
    "y_train_slot = list()\n",
    "for utterance in raw_train:\n",
    "    outs = np.zeros((max_len,len(slot_dict)))\n",
    "    outs = list(outs)\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs[i][slot_dict[slots[i]]] = 1\n",
    "    y_train_slot.append(outs)\n",
    "    \n",
    "y_test_slot = list()\n",
    "for utterance in raw_test:\n",
    "    outs = np.zeros((max_len,len(slot_dict)))\n",
    "    outs = list(outs)\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs[i][slot_dict[slots[i]]] = 1\n",
    "    y_test_slot.append(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4978, 46, 127)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(slot_dict)\n",
    "\n",
    "z_train_slot = list()\n",
    "for utterance in raw_train:\n",
    "    outs = list()\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs.append(slot_dict[slots[i]])\n",
    "    z_train_slot.append(outs)\n",
    "    \n",
    "z_test_slot = list()\n",
    "for utterance in raw_test:\n",
    "    outs = list()\n",
    "    slots = utterance.split('\\t')[1].strip().split(' ')[1:-1]\n",
    "    for i in range(len(slots)):\n",
    "        outs.append(slot_dict[slots[i]])\n",
    "    z_test_slot.append(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(mat):\n",
    "    arr = list()\n",
    "    for ar in mat:\n",
    "        for a in ar:\n",
    "            arr.append(a)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_z_pred_slot(mat,z_act_slot):\n",
    "    ans = list()\n",
    "    for i in range(len(mat)):\n",
    "        ans.append(mat[i][:len(z_act_slot[i])])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(list1, list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        print(\"Size of a the lists not equal\")\n",
    "        return\n",
    "    count = 0.0\n",
    "    for i in range(len(list1)):\n",
    "        if(list1[i] == list2[i]):\n",
    "            count = count + 1\n",
    "            \n",
    "    return count/len(list1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test_slot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 127 and 46 for 'loss/dense_2_loss/mul_1' (op: 'Mul') with input shapes: [?,127], [?,46].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-d2dd1c448c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 830\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# mask should have the same shape as score_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mscore_array\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;31m#  the loss per batch should be proportional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m#  to the number of unmasked samples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    977\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4757\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4758\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4759\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4760\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4761\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 127 and 46 for 'loss/dense_2_loss/mul_1' (op: 'Mul') with input shapes: [?,127], [?,46]."
     ]
    }
   ],
   "source": [
    "lstm_embedding_layer = Embedding(len(embedding_matrix_g), len(embedding_matrix_g[0]), weights=[embedding_matrix_g], input_length=127, \n",
    "                            trainable=False, mask_zero = True)\n",
    "\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "\n",
    "lstm_embedded_sequences = lstm_embedding_layer(sequence_input)\n",
    "\n",
    "lstm = LSTM(200,return_sequences=True)(lstm_embedded_sequences)\n",
    "\n",
    "out = Dense(units=200, activation='relu', kernel_initializer='he_normal')(lstm)\n",
    "\n",
    "out = Dense(units=len(slot_dict), activation='softmax', kernel_initializer='he_normal')(out)\n",
    "\n",
    "graph = Model(inputs=sequence_input, outputs=out)\n",
    "graph.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Layer conv1d_2 does not support masking, but was passed an input_mask: Tensor(\"embedding_3/NotEqual:0\", shape=(?, 46), dtype=bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-54d71b6ace88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    520\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;31m# If the layer returns tensors from its inputs, unmodified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sinchan/.local/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcompute_mask\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    769\u001b[0m                                     \u001b[0;34m' does not support masking, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                                     \u001b[0;34m'but was passed an input_mask: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                                     str(mask))\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0;31m# masking not explicitly supported: return None as mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Layer conv1d_2 does not support masking, but was passed an input_mask: Tensor(\"embedding_3/NotEqual:0\", shape=(?, 46), dtype=bool)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]), weights=[embedding_matrix], input_length=46, trainable=False))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Reshape((23*2,16)))\n",
    "model.add(LSTM(100, dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(100, dropout=0.2, return_sequences=True))\n",
    "model.add(Dense(300,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dense(len(slot_dict), activation=\"sigmoid\",kernel_initializer='he_normal',input_shape=(46,)))\n",
    "model.summary()\n",
    "model.save('rnncnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveBestModel = ModelCheckpoint(filepath=\"/home/sinchan/Videos/slot_filling/g_lstm.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelCheckpoint' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-687bfec3212e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaveBestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelCheckpoint' object has no attribute 'predict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4978 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      " - 35s - loss: 0.6476 - acc: 0.8982 - categorical_accuracy: 0.8982 - val_loss: 0.4383 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91083, saving model to /home/sinchan/Videos/slot_filling/g_lstm.hdf5\n",
      "Epoch 2/10\n",
      " - 25s - loss: 0.3841 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.3284 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91083\n",
      "Epoch 3/10\n",
      " - 24s - loss: 0.2961 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.2721 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91083\n",
      "Epoch 4/10\n",
      " - 24s - loss: 0.2545 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.2415 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91083\n",
      "Epoch 5/10\n",
      " - 24s - loss: 0.2210 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.2115 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91083\n",
      "Epoch 6/10\n",
      " - 24s - loss: 0.1926 - acc: 0.9100 - categorical_accuracy: 0.9100 - val_loss: 0.1844 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91083\n",
      "Epoch 7/10\n",
      " - 24s - loss: 0.1718 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.1694 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91083\n",
      "Epoch 8/10\n",
      " - 25s - loss: 0.1314 - acc: 0.4786 - categorical_accuracy: 0.4786 - val_loss: 0.1092 - val_acc: 0.2114 - val_categorical_accuracy: 0.2114\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91083\n",
      "Epoch 9/10\n",
      " - 24s - loss: 0.0937 - acc: 0.4395 - categorical_accuracy: 0.4395 - val_loss: 0.0906 - val_acc: 0.2210 - val_categorical_accuracy: 0.2210\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91083\n",
      "Epoch 10/10\n",
      " - 25s - loss: 0.0779 - acc: 0.2788 - categorical_accuracy: 0.2788 - val_loss: 0.0810 - val_acc: 0.2502 - val_categorical_accuracy: 0.2502\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb287ad7390>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(train_sequence), np.array(y_train_slot),validation_data=(np.array(test_sequence),np.array(y_test_slot)), epochs=10, batch_size=50, verbose=2,callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred_train = model.predict(train_sequence)\n",
    "lstm_pred_test =  model.predict(test_sequence)\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "lstm_pred_classes_test = lstm_pred_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = open('/home/sinchan/Videos/predSlotTest.txt', 'w')\n",
    "thefile1= open('/home/sinchan/Videos/predSlotTrain.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in lstm_pred_train:\n",
    "  thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "z_pred_slot_test = make_z_pred_slot(lstm_pred_classes_test,z_test_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in z_pred_slot_train:\n",
    "  thefile.write(\"%s\\n\" % item)\n",
    "for item in z_pred_slot_test:\n",
    "  thefile1.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9201695380614848\n",
      "Test F1: 0.8937967439321156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinchan/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train F1: \" + str(f1_score(flatten(z_train_slot),flatten(z_pred_slot_train), average = 'weighted')))\n",
    "print (\"Test F1: \" + str(f1_score(flatten(z_test_slot),flatten(z_pred_slot_test), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stringwe want to go boston\n",
      "[array([ 9,  9,  9,  9, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0])]\n",
      "(1, 18)\n"
     ]
    }
   ],
   "source": [
    "string=list()\n",
    "string1=raw_input(\"Enter the string\")\n",
    "string.append(string1)\n",
    "string=make_sequences(string,word_dict)\n",
    "string=pad_sequences(string, maxlen = 46, padding='post')\n",
    "lstm_pred_train = model.predict(string)\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "print z_pred_slot_train\n",
    "print np.shape(z_pred_slot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOS i want to fly from boston at 838 am and arrive in denver at 1110 in the morning EOS\\t O O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day atis_flight\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to go from boston to anywhere'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-aircraft_code': 81,\n",
       " 'B-airline_code': 51,\n",
       " 'B-airline_name': 26,\n",
       " 'B-airport_code': 80,\n",
       " 'B-airport_name': 88,\n",
       " 'B-arrive_date.date_relative': 77,\n",
       " 'B-arrive_date.day_name': 57,\n",
       " 'B-arrive_date.day_number': 45,\n",
       " 'B-arrive_date.month_name': 44,\n",
       " 'B-arrive_date.today_relative': 106,\n",
       " 'B-arrive_time.end_time': 73,\n",
       " 'B-arrive_time.period_mod': 64,\n",
       " 'B-arrive_time.period_of_day': 6,\n",
       " 'B-arrive_time.start_time': 72,\n",
       " 'B-arrive_time.time': 5,\n",
       " 'B-arrive_time.time_relative': 28,\n",
       " 'B-booking_class': 125,\n",
       " 'B-city_name': 19,\n",
       " 'B-class_type': 23,\n",
       " 'B-compartment': 122,\n",
       " 'B-connect': 83,\n",
       " 'B-cost_relative': 12,\n",
       " 'B-day_name': 96,\n",
       " 'B-day_number': 115,\n",
       " 'B-days_code': 91,\n",
       " 'B-depart_date.date_relative': 25,\n",
       " 'B-depart_date.day_name': 7,\n",
       " 'B-depart_date.day_number': 36,\n",
       " 'B-depart_date.month_name': 38,\n",
       " 'B-depart_date.today_relative': 17,\n",
       " 'B-depart_date.year': 78,\n",
       " 'B-depart_time.end_time': 31,\n",
       " 'B-depart_time.period_mod': 52,\n",
       " 'B-depart_time.period_of_day': 8,\n",
       " 'B-depart_time.start_time': 29,\n",
       " 'B-depart_time.time': 2,\n",
       " 'B-depart_time.time_relative': 22,\n",
       " 'B-economy': 61,\n",
       " 'B-fare_amount': 15,\n",
       " 'B-fare_basis_code': 40,\n",
       " 'B-flight': 126,\n",
       " 'B-flight_days': 66,\n",
       " 'B-flight_mod': 42,\n",
       " 'B-flight_number': 63,\n",
       " 'B-flight_stop': 54,\n",
       " 'B-flight_time': 9,\n",
       " 'B-fromloc.airport_code': 56,\n",
       " 'B-fromloc.airport_name': 33,\n",
       " 'B-fromloc.city_name': 1,\n",
       " 'B-fromloc.state_code': 82,\n",
       " 'B-fromloc.state_name': 75,\n",
       " 'B-meal': 46,\n",
       " 'B-meal_code': 100,\n",
       " 'B-meal_description': 48,\n",
       " 'B-mod': 39,\n",
       " 'B-month_name': 114,\n",
       " 'B-or': 59,\n",
       " 'B-period_of_day': 97,\n",
       " 'B-restriction_code': 85,\n",
       " 'B-return_date.date_relative': 79,\n",
       " 'B-return_date.day_name': 120,\n",
       " 'B-return_date.day_number': 50,\n",
       " 'B-return_date.month_name': 49,\n",
       " 'B-return_date.today_relative': 118,\n",
       " 'B-return_time.period_mod': 112,\n",
       " 'B-return_time.period_of_day': 109,\n",
       " 'B-round_trip': 13,\n",
       " 'B-state_code': 70,\n",
       " 'B-state_name': 104,\n",
       " 'B-stoploc.airport_code': 123,\n",
       " 'B-stoploc.airport_name': 105,\n",
       " 'B-stoploc.city_name': 20,\n",
       " 'B-stoploc.state_code': 99,\n",
       " 'B-time': 58,\n",
       " 'B-time_relative': 107,\n",
       " 'B-today_relative': 98,\n",
       " 'B-toloc.airport_code': 21,\n",
       " 'B-toloc.airport_name': 68,\n",
       " 'B-toloc.city_name': 4,\n",
       " 'B-toloc.country_name': 90,\n",
       " 'B-toloc.state_code': 47,\n",
       " 'B-toloc.state_name': 35,\n",
       " 'B-transport_type': 41,\n",
       " 'I-airline_name': 27,\n",
       " 'I-airport_name': 89,\n",
       " 'I-arrive_date.day_number': 60,\n",
       " 'I-arrive_time.end_time': 74,\n",
       " 'I-arrive_time.period_of_day': 94,\n",
       " 'I-arrive_time.start_time': 84,\n",
       " 'I-arrive_time.time': 53,\n",
       " 'I-arrive_time.time_relative': 93,\n",
       " 'I-city_name': 55,\n",
       " 'I-class_type': 24,\n",
       " 'I-cost_relative': 43,\n",
       " 'I-depart_date.day_number': 37,\n",
       " 'I-depart_date.today_relative': 113,\n",
       " 'I-depart_time.end_time': 32,\n",
       " 'I-depart_time.period_of_day': 111,\n",
       " 'I-depart_time.start_time': 30,\n",
       " 'I-depart_time.time': 3,\n",
       " 'I-depart_time.time_relative': 95,\n",
       " 'I-economy': 62,\n",
       " 'I-fare_amount': 16,\n",
       " 'I-fare_basis_code': 92,\n",
       " 'I-flight_mod': 103,\n",
       " 'I-flight_number': 121,\n",
       " 'I-flight_stop': 71,\n",
       " 'I-flight_time': 10,\n",
       " 'I-fromloc.airport_name': 34,\n",
       " 'I-fromloc.city_name': 11,\n",
       " 'I-fromloc.state_name': 76,\n",
       " 'I-meal_code': 101,\n",
       " 'I-meal_description': 117,\n",
       " 'I-restriction_code': 86,\n",
       " 'I-return_date.date_relative': 116,\n",
       " 'I-return_date.day_number': 110,\n",
       " 'I-return_date.today_relative': 119,\n",
       " 'I-round_trip': 14,\n",
       " 'I-state_name': 124,\n",
       " 'I-stoploc.city_name': 67,\n",
       " 'I-time': 108,\n",
       " 'I-today_relative': 102,\n",
       " 'I-toloc.airport_name': 69,\n",
       " 'I-toloc.city_name': 18,\n",
       " 'I-toloc.state_name': 87,\n",
       " 'I-transport_type': 65,\n",
       " 'O': 0}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to fly from boston at number am and arrive in denver at number in the morning'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.5369780e-03, 1.5283705e-06, 9.7704266e-18, ...,\n",
       "         2.8227021e-12, 4.9106366e-12, 4.1669413e-13],\n",
       "        [5.9651723e-04, 2.1173710e-08, 2.1017464e-20, ...,\n",
       "         1.7471132e-14, 3.1105408e-14, 1.9548601e-15],\n",
       "        [2.4525815e-04, 7.3610296e-09, 1.3384463e-19, ...,\n",
       "         1.7393462e-14, 2.4604479e-14, 1.8238059e-15],\n",
       "        ...,\n",
       "        [2.7371407e-05, 1.5093985e-05, 8.6364878e-08, ...,\n",
       "         2.6072176e-09, 1.6040619e-09, 2.0611772e-09],\n",
       "        [2.9476027e-05, 1.0667843e-05, 4.9358313e-08, ...,\n",
       "         2.2359405e-09, 1.4547628e-09, 1.7246203e-09],\n",
       "        [2.7448412e-05, 1.5059764e-05, 8.7100375e-08, ...,\n",
       "         2.6203293e-09, 1.6080872e-09, 2.0708670e-09]]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(len(embedding_matrix), len(embedding_matrix[0]), weights=[embedding_matrix], input_length=46, trainable=False))\n",
    "model2.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
    "model2.add(MaxPooling1D(pool_size=2))\n",
    "model2.add(Reshape((23*2,50)))\n",
    "model2.add(Dense(300,activation='relu',kernel_initializer='he_normal'))\n",
    "model2.add(Dense(len(slot_dict), activation=\"sigmoid\",kernel_initializer='he_normal',input_shape=(46,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 46, 600)           460200    \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 46, 100)           180100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 23, 100)           0         \n",
      "_________________________________________________________________\n",
      "reshape_20 (Reshape)         (None, 46, 50)            0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 46, 300)           15300     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 46, 127)           38227     \n",
      "=================================================================\n",
      "Total params: 693,827\n",
      "Trainable params: 233,627\n",
      "Non-trainable params: 460,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveBestModel = ModelCheckpoint(filepath=\"/home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4978 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.3468 - acc: 0.9078 - categorical_accuracy: 0.9078 - val_loss: 0.1477 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91083, saving model to /home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.1144 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.1159 - val_acc: 0.9110 - val_categorical_accuracy: 0.9110\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.91083 to 0.91105, saving model to /home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.0907 - acc: 0.9164 - categorical_accuracy: 0.9164 - val_loss: 0.0628 - val_acc: 0.9634 - val_categorical_accuracy: 0.9634\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91105 to 0.96344, saving model to /home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.0293 - acc: 0.9713 - categorical_accuracy: 0.9713 - val_loss: 0.0476 - val_acc: 0.9663 - val_categorical_accuracy: 0.9663\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96344 to 0.96633, saving model to /home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0206 - acc: 0.9757 - categorical_accuracy: 0.9757 - val_loss: 0.0441 - val_acc: 0.9708 - val_categorical_accuracy: 0.9708\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96633 to 0.97084, saving model to /home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0172 - acc: 0.9768 - categorical_accuracy: 0.9768 - val_loss: 0.0441 - val_acc: 0.9703 - val_categorical_accuracy: 0.9703\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97084\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0151 - acc: 0.9755 - categorical_accuracy: 0.9755 - val_loss: 0.0438 - val_acc: 0.9664 - val_categorical_accuracy: 0.9664\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97084\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.0136 - acc: 0.9760 - categorical_accuracy: 0.9760 - val_loss: 0.0481 - val_acc: 0.9667 - val_categorical_accuracy: 0.9667\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97084\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0129 - acc: 0.9754 - categorical_accuracy: 0.9754 - val_loss: 0.0487 - val_acc: 0.9718 - val_categorical_accuracy: 0.9718\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.97084 to 0.97183, saving model to /home/sinchan/Videos/slot_filling/cnne_lstm.hdf5\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.0117 - acc: 0.9750 - categorical_accuracy: 0.9750 - val_loss: 0.0493 - val_acc: 0.9676 - val_categorical_accuracy: 0.9676\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80c29e5950>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(np.array(train_sequence), np.array(y_train_slot),validation_data=(np.array(test_sequence),np.array(y_test_slot)), epochs=10, batch_size=50, verbose=2,callbacks=[saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred_train = model2.predict(train_sequence)\n",
    "lstm_pred_test =  model2.predict(test_sequence)\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "lstm_pred_classes_test = lstm_pred_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "z_pred_slot_test = make_z_pred_slot(lstm_pred_classes_test,z_test_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9818047942394821\n",
      "Test F1: 0.9453120280255638\n"
     ]
    }
   ],
   "source": [
    "print (\"Train F1: \" + str(f1_score(flatten(z_train_slot),flatten(z_pred_slot_train), average = 'weighted')))\n",
    "print (\"Test F1: \" + str(f1_score(flatten(z_test_slot),flatten(z_pred_slot_test), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.4021352313%\n",
      "Test Accuracy: 95.2422522916%\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy: \" + str(accu(flatten(z_train_slot),flatten(z_pred_slot_train))*100) + \"%\")\n",
    "print (\"Test Accuracy: \" + str(accu(flatten(z_test_slot),flatten(z_pred_slot_test))*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinchan/.local/lib/python2.7/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=30, activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(embedding_matrix_w), len(embedding_matrix_w[0]), weights=[embedding_matrix_w], input_length=max_len, trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "conv0 = Conv1D(filters=100, kernel_size=3, activation='relu', padding='same',kernel_initializer='he_normal')(embedded_sequences)\n",
    "pool0 = MaxPooling1D(2)(conv0)\n",
    "#flatten0 = Flatten()(pool0)\n",
    "\n",
    "conv1 = Conv1D(filters=100, kernel_size=3, activation='relu', padding='same',kernel_initializer='he_normal')(embedded_sequences)\n",
    "pool1 = MaxPooling1D(2)(conv1)\n",
    "#flatten1 = Flatten()(pool1)\n",
    "\n",
    "conv2 = Conv1D(filters=100, kernel_size=3, activation='relu', padding='same',kernel_initializer='he_normal')(embedded_sequences)\n",
    "pool2 = MaxPooling1D(2)(conv2)\n",
    "#flatten2 = Flatten()(pool2)\n",
    "\n",
    "# out = Merge(mode='concat')([flatten0,flatten1,flatten2])\n",
    "#out = concatenate([flatten0,flatten1,flatten2])\n",
    "out = concatenate([pool0,pool1,pool2])\n",
    "graph = Model(inputs=sequence_input, outputs=out)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(graph)\n",
    "\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Reshape((23*2,150)))\n",
    "model3.add(LSTM(100, dropout=0.2, return_sequences=True))\n",
    "model3.add(LSTM(100, dropout=0.2, return_sequences=True))\n",
    "model3.add(Dense(output_dim=30, activation='relu'))\n",
    "model3.add(Dense(units=len(slot_dict), activation='softmax',kernel_initializer='he_normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_3 (Model)              (None, 23, 300)           500400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 23, 300)           0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 46, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 46, 100)           100400    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 46, 100)           80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 46, 30)            3030      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46, 127)           3937      \n",
      "=================================================================\n",
      "Total params: 688,167\n",
      "Trainable params: 458,067\n",
      "Non-trainable params: 230,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveBestModel1 = ModelCheckpoint(filepath=\"/home/sinchan/Videos/slot_filling/cnn_lstm3.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4978 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      " - 39s - loss: 1.1702 - acc: 0.5074 - categorical_accuracy: 0.5074 - val_loss: 1.0467 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91083, saving model to /home/sinchan/Videos/slot_filling/cnn4_lstm.hdf5\n",
      "Epoch 2/10\n",
      " - 37s - loss: 1.1325 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 1.0135 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91083\n",
      "Epoch 3/10\n",
      " - 37s - loss: 1.0956 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.9810 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.91083\n",
      "Epoch 4/10\n",
      " - 37s - loss: 1.0596 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.9494 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.91083\n",
      "Epoch 5/10\n",
      " - 37s - loss: 1.0244 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.9187 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91083\n",
      "Epoch 6/10\n",
      " - 43s - loss: 0.9902 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.8889 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91083\n",
      "Epoch 7/10\n",
      " - 42s - loss: 0.9568 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.8599 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91083\n",
      "Epoch 8/10\n",
      " - 37s - loss: 0.9243 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.8319 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91083\n",
      "Epoch 9/10\n",
      " - 36s - loss: 0.8927 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.8048 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91083\n",
      "Epoch 10/10\n",
      " - 37s - loss: 0.8622 - acc: 0.9103 - categorical_accuracy: 0.9103 - val_loss: 0.7788 - val_acc: 0.9108 - val_categorical_accuracy: 0.9108\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad06828590>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(np.array(train_sequence), np.array(y_train_slot),validation_data=(np.array(test_sequence),np.array(y_test_slot)), epochs=10, batch_size=50, verbose=2,callbacks=[saveBestModel1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a1fb3bdda665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlstm_pred_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlstm_pred_classes_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_pred_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlstm_pred_classes_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_pred_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_pred_train = model3.predict(train_sequence)\n",
    "lstm_pred_test =  model3.predict(test_sequence)\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "lstm_pred_classes_test = lstm_pred_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "z_pred_slot_test = make_z_pred_slot(lstm_pred_classes_test,z_test_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.49284069196626834\n",
      "Test F1: 0.4503458217073495\n"
     ]
    }
   ],
   "source": [
    "print (\"Train F1: \" + str(f1_score(flatten(z_train_slot),flatten(z_pred_slot_train), average = 'weighted')))\n",
    "print (\"Test F1: \" + str(f1_score(flatten(z_test_slot),flatten(z_pred_slot_test), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 63.4679715302%\n",
      "Test Accuracy: 60.02837189%\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy: \" + str(accu(flatten(z_train_slot),flatten(z_pred_slot_train))*100) + \"%\")\n",
    "print (\"Test Accuracy: \" + str(accu(flatten(z_test_slot),flatten(z_pred_slot_test))*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_embedding_layer = Embedding(len(embedding_matrix_g), len(embedding_matrix_g[0]), weights=[embedding_matrix_g], input_length=max_len, \n",
    "                            trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "\n",
    "lstm_embedded_sequences = lstm_embedding_layer(sequence_input)\n",
    "\n",
    "lstm = LSTM(200,return_sequences=True)(lstm_embedded_sequences)\n",
    "conv0=Conv1D(filters=100, kernel_size=3, activation='relu', padding='same',kernel_initializer='he_normal')(lstm)\n",
    "pool0 = MaxPooling1D(2)(conv0)\n",
    "pool0=Reshape((23*2,50))(pool0)\n",
    "out = Dense(units=200, activation='relu', kernel_initializer='he_normal')(pool0)\n",
    "\n",
    "out = Dense(units=len(slot_dict), activation='softmax', kernel_initializer='he_normal')(out)\n",
    "\n",
    "model5 = Model(inputs=sequence_input, outputs=out)\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 46, 300)           230100    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 46, 200)           400800    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 46, 100)           60100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 23, 100)           0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 46, 50)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46, 200)           10200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 46, 127)           25527     \n",
      "=================================================================\n",
      "Total params: 726,727\n",
      "Trainable params: 496,627\n",
      "Non-trainable params: 230,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveBestModel15 = ModelCheckpoint(filepath=\"/home/sinchan/Videos/slot_filling/lstmcnn5.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4978 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      " - 41s - loss: 0.3471 - acc: 0.7734 - categorical_accuracy: 0.7734 - val_loss: 0.1621 - val_acc: 0.7512 - val_categorical_accuracy: 0.7512\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75118, saving model to /home/sinchan/Videos/slot_filling/lstmcnn5.hdf5\n",
      "Epoch 2/10\n",
      " - 40s - loss: 0.0949 - acc: 0.8486 - categorical_accuracy: 0.8486 - val_loss: 0.0696 - val_acc: 0.9633 - val_categorical_accuracy: 0.9633\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75118 to 0.96329, saving model to /home/sinchan/Videos/slot_filling/lstmcnn5.hdf5\n",
      "Epoch 3/10\n",
      " - 38s - loss: 0.0423 - acc: 0.9489 - categorical_accuracy: 0.9489 - val_loss: 0.0542 - val_acc: 0.9474 - val_categorical_accuracy: 0.9474\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.96329\n",
      "Epoch 4/10\n",
      " - 37s - loss: 0.0239 - acc: 0.9429 - categorical_accuracy: 0.9429 - val_loss: 0.0420 - val_acc: 0.9613 - val_categorical_accuracy: 0.9613\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.96329\n",
      "Epoch 5/10\n",
      " - 37s - loss: 0.0159 - acc: 0.9125 - categorical_accuracy: 0.9125 - val_loss: 0.0388 - val_acc: 0.9028 - val_categorical_accuracy: 0.9028\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.96329\n",
      "Epoch 6/10\n",
      " - 37s - loss: 0.0106 - acc: 0.8971 - categorical_accuracy: 0.8971 - val_loss: 0.0357 - val_acc: 0.9732 - val_categorical_accuracy: 0.9732\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.96329 to 0.97322, saving model to /home/sinchan/Videos/slot_filling/lstmcnn5.hdf5\n",
      "Epoch 7/10\n",
      " - 37s - loss: 0.0083 - acc: 0.8993 - categorical_accuracy: 0.8993 - val_loss: 0.0359 - val_acc: 0.8624 - val_categorical_accuracy: 0.8624\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97322\n",
      "Epoch 8/10\n",
      " - 43s - loss: 0.0056 - acc: 0.8263 - categorical_accuracy: 0.8263 - val_loss: 0.0368 - val_acc: 0.8845 - val_categorical_accuracy: 0.8845\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97322\n",
      "Epoch 9/10\n",
      " - 40s - loss: 0.0041 - acc: 0.8846 - categorical_accuracy: 0.8846 - val_loss: 0.0419 - val_acc: 0.8458 - val_categorical_accuracy: 0.8458\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97322\n",
      "Epoch 10/10\n",
      " - 42s - loss: 0.0030 - acc: 0.8923 - categorical_accuracy: 0.8923 - val_loss: 0.0360 - val_acc: 0.6661 - val_categorical_accuracy: 0.6661\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb23a51ae50>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(np.array(train_sequence), np.array(y_train_slot),validation_data=(np.array(test_sequence),np.array(y_test_slot)), epochs=10, batch_size=50, verbose=2,callbacks=[saveBestModel15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred_train = model5.predict(train_sequence)\n",
    "lstm_pred_test =  model5.predict(test_sequence)\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "lstm_pred_classes_test = lstm_pred_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "z_pred_slot_test = make_z_pred_slot(lstm_pred_classes_test,z_test_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9985003455299569\n",
      "Test F1: 0.9696274830800998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinchan/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train F1: \" + str(f1_score(flatten(z_train_slot),flatten(z_pred_slot_train), average = 'weighted')))\n",
    "print (\"Test F1: \" + str(f1_score(flatten(z_test_slot),flatten(z_pred_slot_test), average = 'weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.8558718861%\n",
      "Test Accuracy: 97.1846355303%\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Accuracy: \" + str(accu(flatten(z_train_slot),flatten(z_pred_slot_train))*100) + \"%\")\n",
    "print (\"Test Accuracy: \" + str(accu(flatten(z_test_slot),flatten(z_pred_slot_test))*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stringboston today\n",
      "[array([ 1, 17, 17,  0,  0,  0,  0,  0,  0,  0,  0, 93,  0, 93,  0, 93,  0,\n",
      "       93])]\n"
     ]
    }
   ],
   "source": [
    "string=list()\n",
    "string1=raw_input(\"Enter the string\")\n",
    "string.append(string1)\n",
    "string=make_sequences(string,word_dict)\n",
    "string=pad_sequences(string, maxlen = 46, padding='post')\n",
    "lstm_pred_train = model5.predict(string)\n",
    "lstm_pred_classes_train = lstm_pred_train.argmax(axis=-1)\n",
    "z_pred_slot_train = make_z_pred_slot(lstm_pred_classes_train,z_train_slot)\n",
    "print z_pred_slot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOS i want to fly from boston at 838 am and arrive in denver at 1110 in the morning EOS\\t O O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day atis_flight\\n'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-aircraft_code': 81,\n",
       " 'B-airline_code': 51,\n",
       " 'B-airline_name': 26,\n",
       " 'B-airport_code': 80,\n",
       " 'B-airport_name': 88,\n",
       " 'B-arrive_date.date_relative': 77,\n",
       " 'B-arrive_date.day_name': 57,\n",
       " 'B-arrive_date.day_number': 45,\n",
       " 'B-arrive_date.month_name': 44,\n",
       " 'B-arrive_date.today_relative': 106,\n",
       " 'B-arrive_time.end_time': 73,\n",
       " 'B-arrive_time.period_mod': 64,\n",
       " 'B-arrive_time.period_of_day': 6,\n",
       " 'B-arrive_time.start_time': 72,\n",
       " 'B-arrive_time.time': 5,\n",
       " 'B-arrive_time.time_relative': 28,\n",
       " 'B-booking_class': 125,\n",
       " 'B-city_name': 19,\n",
       " 'B-class_type': 23,\n",
       " 'B-compartment': 122,\n",
       " 'B-connect': 83,\n",
       " 'B-cost_relative': 12,\n",
       " 'B-day_name': 96,\n",
       " 'B-day_number': 115,\n",
       " 'B-days_code': 91,\n",
       " 'B-depart_date.date_relative': 25,\n",
       " 'B-depart_date.day_name': 7,\n",
       " 'B-depart_date.day_number': 36,\n",
       " 'B-depart_date.month_name': 38,\n",
       " 'B-depart_date.today_relative': 17,\n",
       " 'B-depart_date.year': 78,\n",
       " 'B-depart_time.end_time': 31,\n",
       " 'B-depart_time.period_mod': 52,\n",
       " 'B-depart_time.period_of_day': 8,\n",
       " 'B-depart_time.start_time': 29,\n",
       " 'B-depart_time.time': 2,\n",
       " 'B-depart_time.time_relative': 22,\n",
       " 'B-economy': 61,\n",
       " 'B-fare_amount': 15,\n",
       " 'B-fare_basis_code': 40,\n",
       " 'B-flight': 126,\n",
       " 'B-flight_days': 66,\n",
       " 'B-flight_mod': 42,\n",
       " 'B-flight_number': 63,\n",
       " 'B-flight_stop': 54,\n",
       " 'B-flight_time': 9,\n",
       " 'B-fromloc.airport_code': 56,\n",
       " 'B-fromloc.airport_name': 33,\n",
       " 'B-fromloc.city_name': 1,\n",
       " 'B-fromloc.state_code': 82,\n",
       " 'B-fromloc.state_name': 75,\n",
       " 'B-meal': 46,\n",
       " 'B-meal_code': 100,\n",
       " 'B-meal_description': 48,\n",
       " 'B-mod': 39,\n",
       " 'B-month_name': 114,\n",
       " 'B-or': 59,\n",
       " 'B-period_of_day': 97,\n",
       " 'B-restriction_code': 85,\n",
       " 'B-return_date.date_relative': 79,\n",
       " 'B-return_date.day_name': 120,\n",
       " 'B-return_date.day_number': 50,\n",
       " 'B-return_date.month_name': 49,\n",
       " 'B-return_date.today_relative': 118,\n",
       " 'B-return_time.period_mod': 112,\n",
       " 'B-return_time.period_of_day': 109,\n",
       " 'B-round_trip': 13,\n",
       " 'B-state_code': 70,\n",
       " 'B-state_name': 104,\n",
       " 'B-stoploc.airport_code': 123,\n",
       " 'B-stoploc.airport_name': 105,\n",
       " 'B-stoploc.city_name': 20,\n",
       " 'B-stoploc.state_code': 99,\n",
       " 'B-time': 58,\n",
       " 'B-time_relative': 107,\n",
       " 'B-today_relative': 98,\n",
       " 'B-toloc.airport_code': 21,\n",
       " 'B-toloc.airport_name': 68,\n",
       " 'B-toloc.city_name': 4,\n",
       " 'B-toloc.country_name': 90,\n",
       " 'B-toloc.state_code': 47,\n",
       " 'B-toloc.state_name': 35,\n",
       " 'B-transport_type': 41,\n",
       " 'I-airline_name': 27,\n",
       " 'I-airport_name': 89,\n",
       " 'I-arrive_date.day_number': 60,\n",
       " 'I-arrive_time.end_time': 74,\n",
       " 'I-arrive_time.period_of_day': 94,\n",
       " 'I-arrive_time.start_time': 84,\n",
       " 'I-arrive_time.time': 53,\n",
       " 'I-arrive_time.time_relative': 93,\n",
       " 'I-city_name': 55,\n",
       " 'I-class_type': 24,\n",
       " 'I-cost_relative': 43,\n",
       " 'I-depart_date.day_number': 37,\n",
       " 'I-depart_date.today_relative': 113,\n",
       " 'I-depart_time.end_time': 32,\n",
       " 'I-depart_time.period_of_day': 111,\n",
       " 'I-depart_time.start_time': 30,\n",
       " 'I-depart_time.time': 3,\n",
       " 'I-depart_time.time_relative': 95,\n",
       " 'I-economy': 62,\n",
       " 'I-fare_amount': 16,\n",
       " 'I-fare_basis_code': 92,\n",
       " 'I-flight_mod': 103,\n",
       " 'I-flight_number': 121,\n",
       " 'I-flight_stop': 71,\n",
       " 'I-flight_time': 10,\n",
       " 'I-fromloc.airport_name': 34,\n",
       " 'I-fromloc.city_name': 11,\n",
       " 'I-fromloc.state_name': 76,\n",
       " 'I-meal_code': 101,\n",
       " 'I-meal_description': 117,\n",
       " 'I-restriction_code': 86,\n",
       " 'I-return_date.date_relative': 116,\n",
       " 'I-return_date.day_number': 110,\n",
       " 'I-return_date.today_relative': 119,\n",
       " 'I-round_trip': 14,\n",
       " 'I-state_name': 124,\n",
       " 'I-stoploc.city_name': 67,\n",
       " 'I-time': 108,\n",
       " 'I-today_relative': 102,\n",
       " 'I-toloc.airport_name': 69,\n",
       " 'I-toloc.city_name': 18,\n",
       " 'I-toloc.state_name': 87,\n",
       " 'I-transport_type': 65,\n",
       " 'O': 0}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD CROSS VALIDATION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
